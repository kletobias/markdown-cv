---
layout: cv
title: Tobias Klein's CV
---
# Tobias Klein


<div id="webaddress">
<a href="unveil.nuggets@gmail.com">unveil.nuggets@gmail.com</a>
| <a href="http://deep-learning-mastery.com">My Portfolio Website</a>
</div>


## Currently

Participating in Machine Learning competitions and expanding my toolkit
full-time.

### Specialized In Machine Learning
<!-- TODO: Fill out Specialized in -->

**Solving Machine Learning Problems using Python** and an iterative process,
that generally incorporates the following steps, possibly going back and forth
between the steps:

1. Define the problem
    - Is it a regression problem
    - Is it a classification problem
    - Is it other higher order problem type
2. Prepare Data
    - Data Preprocessing
    - Feature Selection
    - Feature Engineering
3. Models
    - Candidate Model Selection
    - Hyperparameter Optimization (optional: depending on model)
    - Model Evaluation/Interpretation
    - Finalize Model

### Research interests

Cooling, power series, optics, alchemy, planetary motions, apples.


## Education

### Higher Education

`2009 - 2011` **Heinrich Heine University**, Düsseldorf<br>
- **Subject:** Law (Jura)<br>
- **Courses Completed**
    - Zivilrecht: BGB AT, Schuldrecht AT & BT, Hausarbeit;
    - Strafrecht: STGB AT I-II, Hausarbeit im Strafrecht, Übung im Strafrecht;
    - Öffentliches Recht: Polizeirecht, Grundrechte, Allg. Verwaltungsrecht,
    - Verwaltungsprozessrecht; 1. Teil Kurs im Angloamerikanischen Rechtbr>

`2011 - 2016` **LMU/Freiburg University**, Munich/Freiburg i. Br.<br>
- **Subject:** Mathematics B.Sc.<br>
- **Courses Completed**
    - Linear Algebra I-II | Grades: {'I': 1.7, 'II': 2.3}
    - Analysis I-III | Grades: {'I': 1.3, 'III': 1.7}
    - Stochastic | Grade: 4.0
    - Complex Analysis | Grade: 4.0
    - Futures And Options | Grade: 3.7
    - Exercise In Numerics Using **C** To Implement Methods From Linear Algebra.

`2016 - 2019` **Freiburg University**, Freiburg i. Br.<br>
- **Subject:** Economics Focused Business Administration (BWL Non-Profit &
    Public Management)<br>
- **Final Grade:** 1.6
- **Bachelor Thesis:** 
    - **Title:** *'Data Mining: Hyperparameter Optimization For Real Estate Prediction Models'*
    - **Written Using:** *Latex* & *Python*
    - **Pages:** 69
    - **Grade:** 1.0
- **Relevant Courses Completed** <br>



### School

`1993 - 1994` **Lincoln Elementary School**, Kampala, Uganda

`1994 - 1995` **Kindergarten**, Freiburg i. Br.

`1995 - 1999` **Elementary School**, Zell a.H.

`1999 - 2006` **High School**, Freiburg i. Br.

`2006 - 2006` **Secondary School**, Whistler, Canada<br>
 - Full-time mountain bike junior development program with participation in
     races.

`2006 - 2007` **High School**, Freiburg i. Br.

`2007 - 2008` **High School**, Hamburg<br>
- Graduated with Abitur.



## Articles

<!-- A list is also available [online](http://scholar.google.co.uk/citations?user=LTOTl0YAAAAJ) -->

<p><H4>Automation Using A Test Harness For Deep Learning: Part 1</H4><strong>Description:</strong> How to create and use a custom test harness, that automates many steps of the deep learning testing process. It lowers GPU idle time, lets one build more models, test more parameter combinations in less time. The fastai library for deep learning is used throughout this article.<br>                <strong>Category:</strong> deep learning<br>                <strong>Tags:</strong>  ['deep learning', 'fastai', 'automation', 'learning rate', 'loss function', 'stochastic gradient descent', 'binary image classification']<br>                <strong><a href="https://deep-learning-mastery.com/projects/1st_tm/">Full Article</a></strong><br><br></p>
<p><H4>Automation Using A Test Harness For Deep Learning: Part 2</H4><strong>Description:</strong> This is Part 2 in the series, where we explore how the fastai deep learning  library can be used to conduct structured empirical experiments on a novel and small dataset. The dataset consists of 850 images and an almost uniform distribution for the target labels. There are two labels in total, 'male' and 'female', that are assigned the gender of the model depicted in any of the images in the dataset.<br>                <strong>Category:</strong> deep learning<br>                <strong>Tags:</strong>  ['deep-learning', 'fastai', 'hyperparameter', 'optimization', 'tabular-data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/2nd_tm/">Full Article</a></strong><br><br></p>
<p><H4>Advanced Geospatial Feature Creation</H4><strong>Description:</strong> Extensive cleaning and transformation of tabular data, in order to create geospatial features. Once processed, the results are clean GPS values as "Point" objects in decimal degrees format and names of all subway and suburban train stations within Hamburg, Germany.<br>                <strong>Category:</strong> data preprocessing<br>                <strong>Tags:</strong>  ['data cleaning', 'data transformation', 'geospatial feature creation', 'regular expression', 'shapely', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/advanced-geospatial-feature-creation/">Full Article</a></strong><br><br></p>
<p><H4>Cleaning a webscraped 47 Column Pandas DataFrame Part 1</H4><strong>Description:</strong> Data Preparation Series: Exploring Tabular Data With pandas: An Overview Of Available Tools In The pandas Library.<br>                <strong>Category:</strong> data preprocessing<br>                <strong>Tags:</strong>  ['data exploration', 'first steps', 'introduction', 'pandas', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/data_prep_1/">Full Article</a></strong><br><br></p>
<p><H4>Cleaning a webscraped 47 Column Pandas DataFrame Part 2</H4><strong>Description:</strong> More efficient string data cleaning by using the pyjanitor module and method chaining.<br>                <strong>Category:</strong> data preprocessing<br>                <strong>Tags:</strong>  ['data cleaning', 'pandas', 'regular expressions', 'string manipulation', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/data_prep_2/">Full Article</a></strong><br><br></p>
<p><H4>Cleaning a webscraped 47 Column Pandas DataFrame Part 3</H4><strong>Description:</strong> Extensive cleaning and validation and creation of a valid GPS column from the records, by joining the longitude and latitude columns together using geometry object Point.<br>                <strong>Category:</strong> data preprocessing<br>                <strong>Tags:</strong>  ['data validation', 'dtype timedelta64','geospatial feature engineering', 'pandas', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/data_prep_3/">Full Article</a></strong><br><br></p>
<p><H4>Cleaning a webscraped 47 Column Pandas DataFrame Part 4</H4><strong>Description:</strong> Extensive data cleaning and validation using regular expressions. Showcase of how batch processing several columns of tabular data using pandas, pyjanitor and the re library can look like.<br>                <strong>Category:</strong> data preprocessing<br>                <strong>Tags:</strong>  ['batch processing', 'data validation', 'pandas', 'regular expressions', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/data_prep_4/">Full Article</a></strong><br><br></p>
<p><H4>MySQL Queries Using An AWS Redshift MySQL Database</H4><strong>Description:</strong> This article shows how one can use Python to import CSV files using Pandas into a MySQL database hosted on AWS using Redshift and how to formulate basic MySQL queries to get the data of interest.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['mysql', 'AWS', 'pandas', 'tabular data', 'query']<br>                <strong><a href="https://deep-learning-mastery.com/projects/mysql-redshift-1/">Full Article</a></strong><br><br></p>
<p><H4>Datacamp Concrete Regression Challenge</H4><strong>Description:</strong> This is the notebook I created to solve the datacamp concrete challenge within an hour. There are explanations for most of the code in this article and we look deeper into the workings of the Lasso regression model.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['cross validation', 'lasso regression', 'math', 'multivariate regression', 'regression analysis']<br>                <strong><a href="https://deep-learning-mastery.com/projects/regression60min_datacamp-concrete-challenge/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 1</H4><strong>Description:</strong> Preprocessing Data: Visualizing missing values on an 80 feature dataset. Strategies for filling missing values and using categorical embeddings.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['categorical embeddings', 'data preprocessing', 'fastai', 'fill strategies', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-1/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 2</H4><strong>Description:</strong> Feature selection using model DecisionTreeRegressor from sklearn and the feature_importances_ method which is tested for deviations in its score.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['decision tree regressor', 'feature importance', 'feature selection', 'sklearn', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-2/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 3</H4><strong>Description:</strong> RandomForestRegressor using feature_importances_ and out-of-bag error to asses model performance.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['feature importance', 'feature selection', 'out-of-bag error', 'random forest', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-3/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 4</H4><strong>Description:</strong> Interpretation Using Advanced Statistical Visualizations. Dendrogram, Spearman rank correlation, partial dependence plot, impact of independent variables for sample on predictions.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['dendrogram', 'partial dependence', 'spearman rank correlation', 'tabular data', 'treeinterpreter']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-4/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 5</H4><strong>Description:</strong> Out-of-domain problem: What it is, why it is important, how to spot it and how to deal with it.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['feature importance', 'model accuracy', 'out-of-domain problem', 'random forest', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-5/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 6</H4><strong>Description:</strong> Kaggle Submission 1: Training RandomForestRegressor, fastai deep learning model using hyperparameter optimization techniques. Preprocessing of Kaggle test data.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['data preprocessing', 'fastai', 'hyperparameter optimization', 'random forest', 'tabular data']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-6/">Full Article</a></strong><br><br></p>
<p><H4>Deep Dive Tabular Data Pt. 7</H4><strong>Description:</strong> Kaggle Submission 2: tabular_learner deep learning estimator optimized using manual hyperparameter optimization. XGBRegressor using RandomizedSearchCV and sampling from continuous parameter distributions.<br>                <strong>Category:</strong> tabular data<br>                <strong>Tags:</strong>  ['hyperparameter optimization', 'random search', 'tabular data', 'tabular_learner', 'xgboost regressor']<br>                <strong><a href="https://deep-learning-mastery.com/projects/tabular_kaggle-7/">Full Article</a></strong><br><br></p>
<p><H4>The Math Behind "Stepping The Weights"</H4><strong>Description:</strong> In this article we highlight a key concept in the Stochastic Gradient Descent and explore the basics, that this optimization algorithm is derived of.<br>                <strong>Category:</strong> deep learning<br>                <strong>Tags:</strong>  ['deep learning', 'math', 'ordinary least squares', 'partial derivate', 'stochastic gradient descent']<br>                <strong><a href="https://deep-learning-mastery.com/projects/theory_batch_gradient_descent/">Full Article</a></strong><br><br></p>
### Journals

`1669`
Newton Sir I, De analysi per æquationes numero terminorum infinitas. 

`1669`
Lectiones opticæ.

etc. etc. etc.


## Occupation

`1600`
__Royal Mint__, London

- Warden
- Minted coins

`1600`
__Lucasian professor of Mathematics__, Cambridge University



<!-- ### Footer

Last updated: January 2023 -->

