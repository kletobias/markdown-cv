
**Part 1: Basic Automation For Deep Learning**

*How to create and use a custom test harness, that automates many steps of the
deep learning testing process. It lowers GPU idle time, lets one build more
models, test more parameter combinations in less time. The fastai library for
deep learning is used throughout this article.*


**Part 2: Hyperparameter Optimization An Example**

*This is Part 2 in the series, where we explore how the fastai deep learning
library can be used to conduct structured empirical experiments on a novel and
small dataset. The dataset consists of 850 images and an almost uniform
distribution for the target labels. There are two labels in total, 'male' and
'female', that are assigned the gender of the model depicted in any of the
images in the dataset.*


**Advanced Geospatial Feature Creation**

*Extensive cleaning and transformation of tabular data, in order to create
geospatial features. Once processed, the results are clean GPS values as "Point"
objects in decimal degrees format and names of all subway and suburban train
stations within Hamburg, Germany.*


**Cleaning a 47 Column Pandas DataFrame Part 1**

*Data Preparation Series: Exploring Tabular Data With pandas: An Overview Of
Available Tools In The pandas Library*


**Cleaning a 47 Column Pandas DataFrame Part 2**

*More efficient string data cleaning by using the pyjanitor module and method
chaining.*


**Cleaning a 47 Column Pandas DataFrame Part 3**

*Extensive cleaning and validation and creation of a valid GPS column from the
records, by joining the longitude and latitude columns together using geometry
object Point.*


**Cleaning a 47 Column Pandas DataFrame Part 4**

*Extensive data cleaning and validation using regular expressions. Showcase of
how batch processing several columns of tabular data using pandas, pyjanitor and
the re library can look like.*


**MySQL Queries Using An AWS Redshift MySQL Database**

*This article shows how one can use Python to import CSV files using Pandas into
a MySQL database hosted on AWS using Redshift and how to formulate basic MySQL
queries to get the data of interest.*


**datacamp concrete regression challenge**

*This is the notebook I created to solve the datacamp concrete challenge within
an hour. There are explanations for most of the code in this article and we look
deeper into the workings of the Lasso regression model.*


**Deep Dive Tabular Data Pt. 1**

*Preprocessing Data: Visualizing missing values on an 80 feature dataset.
Strategies for filling missing values and using categorical embeddings.*


**Deep Dive Tabular Data Pt. 2**

*Feature selection using model DecisionTreeRegressor from sklearn and the
feature_importances_ method which is tested for deviations in its score.*


**Deep Dive Tabular Data Pt. 3**

*RandomForestRegressor using feature_importances_ and out-of-bag error to asses
model performance.*


**Deep Dive Tabular Data Pt. 4**

*Interpretation Using Advanced Statistical Visualizations. Dendrogram, Spearman
rank correlation, partial dependence plot, impact of independent variables for
sample on predictions.*


**Deep Dive Tabular Data Pt. 5**

*Out-of-domain problem: What it is, why it is important, how to spot it and how
to deal with it.*


**Deep Dive Tabular Data Pt. 6**

*Kaggle Submission 1: Training RandomForestRegressor, fastai deep learning model
using hyperparameter optimization techniques. Preprocessing of Kaggle test
data.*


**Deep Dive Tabular Data Pt. 7**

*Kaggle Submission 2: tabular_learner deep learning estimator optimized using
manual hyperparameter optimization. XGBRegressor using RandomizedSearchCV and
sampling from continuous parameter distributions.*


**The Math Behind "Stepping The Weights"**

*In this article we highlight a key concept in the Stochastic Gradient Descent
and explore the basics, that this optimization algorithm is derived of.*

